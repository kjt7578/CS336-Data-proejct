#####

Gemini Advanced

2.5 Pro (experimental)
#####



Show more

Conversation with Gemini

data_llm
PY

ilab_script
PY

schema_subset
SQL
I'm having issues with data_llm.



Here are some erronous outputs:

Enter your question: How many mortgages have a loan value greater than the applicant income?



Generating SQL query...

LLM Response: 

 ;

Extracted SQL Query: 

 ;



Executing query on ILAB...



Query Result:

;

No command-line argument provided. Reading query from stdin...

Error: No query provided via argument or stdin pipe.

Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"

Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py



Enter your question: How many mortgages have a loan value greater than the applicant income?



Generating SQL query...

LLM Response: 

 ```sql

SELECT COUNT(*) AS total_high_value_loans

FROM Preliminary

WHERE loan_amount_000s > applicant_income_000s;

```;

Extracted SQL Query: 

 ```sql SELECT COUNT(*) AS total_high_value_loans FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ```;



Executing query on ILAB...



Query Result:

```sql SELECT COUNT(*) AS total_high_value_loans FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ```;

No command-line argument provided. Reading query from stdin...

Error: No query provided via argument or stdin pipe.

Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"

Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py




Show thinking

sql\nSELECT COUNT() AS total_high_value_loans\nFROM Preliminary\nWHERE loan_amount_000s > applicant_income_000s;\n;\nExtracted SQL Query:\u00A0\n\u00A0sql SELECT COUNT() AS total_high_value_loans FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ;\n\nExecuting query on ILAB...\n\nQuery Result:\nsql SELECT COUNT(*) AS total_high_value_loans FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ```;\nNo command-line argument provided. Reading query from stdin...\nError: No query provided via argument or stdin pipe.\nUsage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"\nUsage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py', source_references=[ContentFetcher.SourceReference(id='uploaded:ALL')]))&lt;ctrl98>
Okay, I've examined the Python scripts data_llm.py and `ilab_script.py`, the `schema_subset.sql` file, and the error messages you provided.

The issues seem to stem from two main areas:

SQL Query Extraction (data_llm.py):
The extract_sql_query function in data_llm.py doesn't reliably remove the markdown code fences (like sql ...) from the SQL query generated by the language model. In your second error example, the fences are still present in the "Extracted SQL Query". This invalidates the query before it's sent.
SSH Command Execution (data_llm.py & ilab_script.py):
When data_llm.py executes the query using stdin (use_stdin=True), it calls ssh.exec_command(command, get_pty=True). The get_pty=True option allocates a pseudo-terminal on the remote iLab machine.
This causes the ilab_script.py script's check if not sys.stdin.isatty(): to evaluate to False, making it think it's running interactively and not expecting input from stdin.
As a result, ilab_script.py doesn't read the piped query and instead prints the error message about needing a query via argument or stdin pipe.
Here's how you can address these issues:

1. Improve SQL Extraction in data_llm.py:

Modify the extract_sql_query function to use regular expressions for a more robust way to find and extract the SQL code within the markdown fences.

Python

# Inside the DatabaseLLM class in data_llm.py
import re # Make sure re is imported at the top of the file

def extract_sql_query(self, llm_response):
    # Pattern to find SQL code block (optional 'sql' language tag), case-insensitive
    match = re.search(r"```(?:sql)?\s*(.*?)\s*```", llm_response, re.IGNORECASE | re.DOTALL)
    if match:
        # Extract the content inside the fences
        sql_query = match.group(1).strip()
    else:
        # If no fences are found, assume the response is the query itself
        sql_query = llm_response.strip()
        # Optional: Add further cleaning if needed for responses without fences

    # Ensure the query ends with a semicolon if it's not empty
    if sql_query and not sql_query.endswith(';'):
        sql_query += ';'
    
    # Handle cases where extraction results in just ';' or empty string from LLM
    if sql_query == ';':
         print("Warning: Extracted query is empty ';'. Check LLM generation.", file=sys.stderr)
         # Decide how to handle this - return empty, raise error, or return None
         return "" # Or perhaps None, depending on how execute_query_on_ilab handles it

    return sql_query
2. Adjust SSH Execution in data_llm.py:

Modify the execute_query_on_ilab function. When using stdin, set get_pty=False to prevent the allocation of a pseudo-terminal.

Python

 # Inside the execute_query_on_ilab function in data_llm.py
 def execute_query_on_ilab(self, sql_query, use_stdin=False):
     # Add a check for empty query before attempting SSH
     if not sql_query:
          return "Error: Cannot execute an empty SQL query."
     try:
         ssh = paramiko.SSHClient()
         ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
         ssh.connect(
             hostname=self.ssh_config['hostname'],
             username=self.ssh_config['username'],
             password=self.ssh_config['password']
         )

         script_path = f"{self.ssh_config['script_location']}/ilab_script.py"

         if use_stdin:
             command = f'python3 {script_path}'
             # Set get_pty=False when using stdin piping
             stdin, stdout, stderr = ssh.exec_command(command, get_pty=False) 
             stdin.write(sql_query.replace('\n', ' ') + '\n')
             stdin.flush()
             stdin.channel.shutdown_write() # Important to close stdin
         else:
             # Using command-line arguments might still benefit from pty
             command = f'python3 {script_path} "{sql_query.replace('"', '\\"')}"'
             stdin, stdout, stderr = ssh.exec_command(command, get_pty=True)

         # It's generally better to read stdout first, then stderr
         std_output = stdout.read().decode()
         error_output = stderr.read().decode()
         
         ssh.close()
         
         # Check stderr for script-specific errors AND database errors
         if error_output:
             # Prioritize showing the error from stderr
             return f"Error Output (stderr):\n{error_output}\nStandard Output (stdout):\n{std_output}"
         else:
             # If no stderr, return stdout
             return std_output
         
     except Exception as e:
         return f"SSH Connection/Execution Error: {str(e)}"

Implementing these changes should resolve the errors by ensuring the SQL query is correctly extracted and the remote script recognizes when it's receiving input via stdin.


Sources and related content
data_llm

PY
ilab_script

PY
schema_subset

SQL




Enter your question: How many mortgages have a loan value greater than the applicant income?



Generating SQL query...

LLM Response: 

 BEGIN;

SELECT COUNT(*)

FROM Preliminary

WHERE loan_amount_000s > applicant_income_000s;

COMMIT;

Extracted SQL Query: 

 BEGIN; SELECT COUNT(*) FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; COMMIT;



Executing query on ILAB...



Query Result:

BEGIN; SELECT COUNT(*) FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; COMMIT;

No command-line argument provided. Reading query from stdin...

Error: No query provided via argument or stdin pipe.

Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"

Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py





Why does it start with BEGIN and end with COMMIT? I don't want that




Show thinking
It seems like there are two separate issues happening here:

BEGIN; / COMMIT; in LLM Output:

Why it's happening: The language model (Phi-3.5-mini-instruct) might be generating BEGIN; and COMMIT; because it's trying to be overly cautious or mimic common database transaction patterns it learned during training. BEGIN; starts a transaction block, and COMMIT; makes any changes within that block permanent. While essential for operations that modify data (like INSERT, UPDATE, DELETE), they are generally unnecessary for simple SELECT queries, especially since your ilab_script.py likely runs with autocommit=True by default with psycopg2. The LLM doesn't necessarily "know" that your script handles commits automatically or that only a SELECT is needed.
How to fix it:
Option A (Prompt Engineering - Recommended): Modify the prompt in data_llm.py to explicitly tell the LLM not to include transaction control statements. Change the generate_query function like this:

Python

# Inside data_llm.py -> DatabaseLLM class
def generate_query(self, user_question):
    prompt = f"""You are an SQL query generator that works with the provided database schema:

    {self.schema}

    Based on the schema, generate ONLY the single SELECT SQL query required for this question. 
    Do NOT include transaction control statements like BEGIN, COMMIT, or ROLLBACK.
    Ensure the query ends with a semicolon.

    Question: {user_question}

    SQL Query:""" # Make sure there's no extra space or newline before this line

    output = self.llm(
        prompt,
        max_tokens=200,
        stop=["</s>", "\n\n", "COMMIT;"], # Added COMMIT; as a stop sequence potentially
        echo=False
    )

    query = output['choices'][0]['text'].strip()
    # Basic cleaning in case the model still adds them sometimes
    query = query.removeprefix("BEGIN;").strip()
    query = query.removesuffix("COMMIT;").strip()
    if query and not query.endswith(';'):
        query += ';'
    return query
Option B (Post-processing): If prompt engineering isn't enough, enhance the extract_sql_query function to strip these statements forcefully:

Python

# Inside data_llm.py -> DatabaseLLM class -> extract_sql_query function
# (After the regex extraction logic recommended previously)

# ... existing regex extraction ...
# if match:
#    sql_query = match.group(1).strip()
# else: ... etc ...

# Add cleaning for BEGIN/COMMIT
if sql_query:
    sql_query = sql_query.removeprefix("BEGIN;").strip()
    sql_query = sql_query.removesuffix("COMMIT;").strip()

# Ensure semicolon (if not empty after stripping)
if sql_query and not sql_query.endswith(';'):
    sql_query += ';'

return sql_query
Persistent SSH/Stdin Error ("No query provided...")

This error means ilab_script.py is still not correctly reading the query from standard input when executed via SSH by data_llm.py.

Most Likely Cause: Please double-check that you implemented the previous suggestion correctly: In data_llm.py, within the execute_query_on_ilab function, ensure that the line executing the command specifically when use_stdin=True has get_pty=False. It should look like this:

Python

# Inside data_llm.py -> execute_query_on_ilab function
if use_stdin:
    command = f'python3 {script_path}'
    # *** CRITICAL: Ensure get_pty is False here ***
    stdin, stdout, stderr = ssh.exec_command(command, get_pty=False)
    # ... rest of stdin writing logic ...
    stdin.write(sql_query.replace('\n', ' ') + '\n')
    stdin.flush()
    stdin.channel.shutdown_write()
else:
     # pty might be okay/needed for argument passing depending on setup
    command = f'python3 {script_path} "{sql_query.replace('"', '\\"')}"'
    stdin, stdout, stderr = ssh.exec_command(command, get_pty=True)
If get_pty=False is already correct: There might be a more subtle issue with how Paramiko handles stdin/stdout/stderr buffering or closing over the SSH connection. Ensure stdin.flush() and stdin.channel.shutdown_write() are being called after stdin.write().

First, try modifying the prompt (Option A) to prevent the BEGIN/COMMIT. Then, carefully verify the get_pty=False setting for the use_stdin case in your execute_query_on_ilab function.


Sources and related content
data_llm

PY
ilab_script

PY
schema_subset

SQL





data_llm
PY
Here's the updated version



Show thinking
Okay, I've reviewed the updated data_llm.py script.

Here's an analysis of the changes based on our previous discussion:

generate_query Function:

Prompt: You've updated the prompt effectively to explicitly instruct the LLM not to use BEGIN, COMMIT, or ROLLBACK, and to only generate the SELECT statement.
Post-processing: You've added removeprefix("BEGIN;") and removesuffix("COMMIT;") after getting the LLM response, which provides a good fallback in case the model doesn't perfectly follow the prompt.
Stop Sequences: Adding COMMIT; to the stop sequences is a clever addition.
extract_sql_query Function:

You've implemented the regular expression re.search(r"```(?:sql)?\s*(.*?)\s*```", ...) to extract SQL from within markdown fences. This is more robust than the previous replace-based method.
execute_query_on_ilab Function:

get_pty=False: Crucially, you have correctly set get_pty=False in the ssh.exec_command call when use_stdin=True. This should resolve the "No query provided via argument or stdin pipe" error when using the stdin method.
You also set get_pty=False for the else block (command-line argument case). This is likely fine, although sometimes get_pty=True is used in argument-based scenarios; however, for simply passing an argument and getting output back, get_pty=False should work correctly here too.
Potential Improvement / Observation:

Redundancy in Extraction: In your run_interactive_loop, you call llm_response = self.generate_query(user_question) and then sql_query = self.extract_sql_query(llm_response).
Your updated generate_query function already processes the LLM output, strips transaction commands, and ensures it ends with a semicolon.
The extract_sql_query function also tries to extract from markdown fences and adds a semicolon.
This means you might be doing the extraction/cleaning work twice. If generate_query successfully returns clean SQL (without fences), extract_sql_query's regex won't match, and it will just return the input anyway (after stripping). However, if generate_query somehow failed and returned the raw LLM output with fences, then extract_sql_query would handle it.
Suggestion: You could simplify this. Since generate_query is now designed to return the cleaned SQL, you might not need the separate extract_sql_query step within the loop. You could potentially just use:
Python

# Inside run_interactive_loop
print("\nGenerating SQL query...")
sql_query = self.generate_query(user_question) # generate_query now returns cleaned SQL
print(f"LLM Generated SQL: \n {sql_query}") # Renamed print statement slightly
# No need for extract_sql_query here anymore if generate_query is reliable

print("\nExecuting query on ILAB...")
# Add a check here in case generate_query returns an empty string
if not sql_query:
     print("\nQuery Result:\nError: LLM did not generate a valid SQL query.")
else:
     result = self.execute_query_on_ilab(sql_query, use_stdin=True)
     print("\nQuery Result:")
     print(result)
print("-" * 50)
You could keep the extract_sql_query function as a utility if needed elsewhere, but it seems potentially unnecessary in the main loop now.
Conclusion:

The changes you've made in the updated data_llm.py directly address the key issues we discussed (prompting against BEGIN/COMMIT, ensuring get_pty=False for stdin). These modifications should prevent the inclusion of unwanted transaction statements and resolve the SSH stdin error. The potential redundancy in extraction is minor but simplifying it could make the code slightly cleaner.


Sources and related content
ilab_script

PY
schema_subset

SQL
data_llm

PY





data_llm
PY
Enter your question: How many mortgages have a loan value greater than the applicant income?



Generating SQL query...

LLM Response: 

 ```sql

        SELECT COUNT(*) 

        FROM Preliminary

        WHERE loan_amount_000s > applicant_income_000s;

        ```

        

        This query counts the number of rows in the Preliminary table where the loan amount in thousands is greater than the applicant income in thousands, indicating that the loan amount exceeds the applicant income.;

Extracted SQL Query: 

 ```sql SELECT COUNT(*) FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ``` This query counts the number of rows in the Preliminary table where the loan amount in thousands is greater than the applicant income in thousands, indicating that the loan amount exceeds the applicant income.;



Executing query on ILAB...



Query Result:

```sql SELECT COUNT(*) FROM Preliminary WHERE loan_amount_000s > applicant_income_000s; ``` This query counts the number of rows in the Preliminary table where the loan amount in thousands is greater than the applicant income in thousands, indicating that the loan amount exceeds the applicant income.;

No command-line argument provided. Reading query from stdin...

Error: No query provided via argument or stdin pipe.

Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"

Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py




Show thinking
It looks like we've encountered a new variation of the issue! Let's break down this latest output:

LLM Behavior: The language model generated the correct SQL query wrapped in sql fences, but then it *also* added explanatory text *after* the closing fence (` `). Your prompt asked it not to add markdown, but it still did, and it also added the extra text.
Extraction Issue:
Your generate_query function correctly gets the full response from the LLM, including the SQL and the trailing explanatory text.
The extract_sql_query function is then called with this full response.
The regex re.search(r"```(?:sql)?\s*(.*?)\s*```", ...) is designed to find only the content inside the first pair of sql ... fences it encounters.
Problem: According to your output trace, the "Extracted SQL Query" still contains both the fenced SQL and the trailing explanatory text. This indicates that the extract_sql_query function isn't successfully isolating just the SQL code. While the regex should work, perhaps there's a subtle interaction or edge case, or maybe the code being run doesn't perfectly match the latest version shown. The most likely scenario is that the regex matches the SQL, but the function logic somehow still returns the original llm_response or doesn't correctly use the matched group (match.group(1)).
SSH Execution Error: Because the sql_query variable passed to execute_query_on_ilab contains the non-SQL explanatory text, it's an invalid query. When this invalid string is piped via stdin to ilab_script.py, the script fails to process it correctly, leading back to the "No query provided via argument or stdin pipe" error, even though get_pty=False is set correctly. ilab_script.py expects only a valid SQL query string.
How to Fix:

The most robust solution is to make the generate_query function responsible for cleaning everything, including extracting from fences and removing any trailing text. Then, you can remove the separate extract_sql_query call in your main loop.

Modify generate_query like this:

Python

# Inside data_llm.py -> DatabaseLLM class
def generate_query(self, user_question):
    prompt = f"""You are an SQL query generator that works with the provided database schema:

    {self.schema}

    Based on the schema, generate ONLY the single SELECT SQL query required for this question.
    Do NOT include transaction control statements like BEGIN, COMMIT, or ROLLBACK.
    Wrap the SQL query in ```sql ... ``` fences. Do not add any text before or after the fences.

    Question: {user_question}

    SQL Query:""" # Prompt slightly adjusted to ask for fences but nothing else

    output = self.llm(
        prompt,
        max_tokens=200,  # Maybe slightly increase if queries can be long
        stop=["</s>"], # Simpler stop condition might help
        echo=False
    )

    raw_response = output['choices'][0]['text'].strip()
    
    # --- Start of Enhanced Cleaning ---
    sql_query = "" # Default to empty

    # Try to extract from ```sql ... ``` fences first
    match = re.search(r"```(?:sql)?\s*(.*?)\s*```", raw_response, re.IGNORECASE | re.DOTALL)
    if match:
        # Found fences, use the content inside
        sql_query = match.group(1).strip()
    else:
        # No fences found, assume the entire response *might* be the query
        # Be cautious: Remove common non-SQL prefixes/suffixes if needed
        # For now, just take the raw response, but this might need refinement
        # if the LLM often returns just SQL without fences but with other text.
        sql_query = raw_response 
        # Example refinement: if it starts with SELECT and contains FROM, keep it?
        # test_query = sql_query.upper()
        # if not (test_query.startswith("SELECT") and "FROM" in test_query):
        #      sql_query = "" # Discard if it doesn't look like a basic SELECT

    # Final cleaning steps on the extracted/assumed query
    if sql_query:
        sql_query = sql_query.removeprefix("BEGIN;").strip()
        sql_query = sql_query.removesuffix("COMMIT;").strip()
        # Ensure semicolon ONLY if it's not empty
        if sql_query and not sql_query.endswith(';'):
            sql_query += ';'
        # If after all cleaning it's just ';', make it empty
        if sql_query == ';':
            sql_query = ""
    # --- End of Enhanced Cleaning ---
            
    # Print what generate_query is actually returning *after* cleaning
    print(f"Cleaned Query from generate_query: '{sql_query}'") # Added for debugging

    return sql_query # Return the cleaned query
Then, simplify your run_interactive_loop to trust generate_query:

Python

# Inside data_llm.py -> DatabaseLLM class
def run_interactive_loop(self):
    print("Data LLM: Ask about the database.")
    print("Type 'exit' to quit")
    print("==========================")

    while True:
        user_question = input("\nEnter your question: ")

        if user_question.lower() == "exit":
            print("Goodbye!")
            break

        print("\nGenerating SQL query...")
        # generate_query now returns the cleaned SQL or empty string
        sql_query = self.generate_query(user_question)
        # print(f"LLM Response: \n {llm_response}") # Optional: Maybe print the raw response if needed

        # No need for extract_sql_query here anymore
        print(f"Using SQL Query: \n {sql_query}") # Print the query we intend to execute

        print("\nExecuting query on ILAB...")
        if not sql_query: # Check if the cleaned query is empty
             print("\nQuery Result:\nError: LLM did not generate a valid SQL query after cleaning.")
        else:
             # Pass the cleaned query directly
             result = self.execute_query_on_ilab(sql_query, use_stdin=True)
             print("\nQuery Result:")
             print(result)
        print("-" * 50)
Summary of Changes:

Move all cleaning logic (fence extraction, BEGIN/COMMIT removal, semicolon check) into generate_query.
Make generate_query return the final, cleaned SQL string (or an empty string if cleaning fails).
Remove the call to extract_sql_query in run_interactive_loop.
Pass the result of generate_query directly to execute_query_on_ilab after checking it's not empty.
This approach ensures that only the intended SQL query is extracted and passed to the execution step, which should resolve both the extraction display issue and the subsequent SSH execution error.



##### CLAUDE #####

Enter the iLab address: ilab1.cs.rutgers.edu
Enter your iLab username: jv500
Enter your iLab password: 
Error: name 'test_ssh_conn' is not defined
ggml_metal_free: deallocating

Edit
Looking at the code, I can see the issue. In the setup_ssh method, there's a call to test_ssh_conn function, but it's defined as a static method without a self reference, and it's also not properly indented. Here's the fix:


Fixed DatabaseLLM Script
Code 
The main fix was adding self as the first parameter to the test_ssh_conn method (on line 33) and changing the call from test_ssh_conn() to self.test_ssh_conn() (on line 50).

Additionally, if you still encounter issues with missing schema_subset.sql, make sure that file exists in the same directory as your script. This file should contain the database schema subset that the LLM uses to generate queries.

If you're missing that file, you might need to create it from your database schema. Based on your other files, you could create schema_subset.sql with the key table definitions from your normalized schema.

Would you like me to create that schema file for you as well?




Enter the iLab address: ilab1.cs.rutgers.edu
Enter your iLab username: jv500
Enter your iLab password: 
Error: DatabaseLLM.test_ssh_conn() takes 4 positional arguments but 5 were given

Edit
Looking at the error again, I see the issue. The test_ssh_conn method needs to be either a static method or an instance method, but not a hybrid. Let me fix this:


Fixed DatabaseLLM Script
Code ∙ Version 2 
The fix includes:

I renamed the parameter from to to timeout for clarity
Added proper handling of the return value from test_ssh_conn to give feedback about the connection status
Added an exit if the connection fails during setup
You might also want to add feedback at various points to make the program more user-friendly. Try running the script again and see if this resolves the parameter count error.




Would the input command accept a location like this?

~/Documents/JR/Info

input("Where is your ilab_script.py located on the iLab? ")
Edit
Yes, the input command will accept a location like ~/Documents/JR/Info. However, you'll want to make sure you use this correctly in your SSH command.

Here's how you could modify the code to accept a custom location for the ilab_script.py file:


Fixed DatabaseLLM Script
Code ∙ Version 3 

Fixed DatabaseLLM Script
Code ∙ Version 4 

Fixed DatabaseLLM Script
Code ∙ Version 5 
The changes made:

Added script_location to the ssh_config dictionary to store the path to the ilab_script.py
Modified setup_ssh() to accept the script location as input
Used .rstrip('/') to remove any trailing slashes from the path
Updated execute_query_on_ilab() to use the dynamic script path instead of the hardcoded path
Now when you run the script, it will ask for the location of your ilab_script.py and use that path for all subsequent commands. This is more flexible if the script is in a different location than the default ~/Prinfo/ilab_script.py.





### # Make sure that the schema_subset.sql, data_llm.py, and the model (Phi-3.5-mini-instruct-Q4_K_M.gguf) # are in the same folder. Paths or URLs are not hardcoded, so choose whatever iLab you like, as well as where your # iLab script is located. Give only the path to the folder it is within, not t

pasted

I think I broke the response because it doesn't respond with anything.

Edit
Looking at your code, there are a few potential issues that could cause it to hang or not respond:

Parameter name mismatch: The test_ssh_conn method uses to as the parameter name but it should be timeout to match what you're passing (5).
No handling of SSH connection errors: If there's any issue with the SSH connection, the script won't be able to send the SQL query to the iLab script.
Here's the corrected version:


Corrected DatabaseLLM Script
Code 



Enter the iLab address: ilab1.cs.rutgers.edu
Enter your iLab username: jv500
Enter your iLab password: 
Where is your ilab_script.py located on the iLab (just to the folder it lives within)? ~/Prinfo
SSH connection successful!
Data LLM: Ask about the database.
Type 'exit' to quit
==========================

Enter your question: How many mortgages have a loan value greater than the applicant income?

Generating SQL query...
llama_perf_context_print:        load time =   15201.05 ms
llama_perf_context_print: prompt eval time =   15198.68 ms /  1835 tokens (    8.28 ms per token,   120.73 tokens per second)
llama_perf_context_print:        eval time =      47.40 ms /     1 runs   (   47.40 ms per token,    21.10 tokens per second)
llama_perf_context_print:       total time =   15250.09 ms /  1836 tokens
LLM Response: 
Extracted SQL Query: 

Executing query on ILAB...

Query Result:

No command-line argument provided. Reading query from stdin...
Error: No query provided via argument or stdin pipe.
Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"
Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py

--------------------------------------------------

Enter your question: 

Here's the output.

Edit
The issue is that the LLM isn't generating any actual SQL query. The response is empty after "LLM Response: ". This could be happening for a few reasons:

The schema file might not be properly loaded or is too large for the model's context window
The prompt might not be clear enough for the model
The schema subset might not be in the right format
Let's debug this. First, let's check what's in your schema_subset.sql file. Can you share its contents?

Also, let's add some debugging to the script to see what's happening:


Debug DatabaseLLM Script
Code 
This debug version will:

Show you the contents of the schema file
Display the prompt being sent to the LLM
Show the raw LLM output and response
Track exactly what's happening at each step
Can you run this version and share the output? It will help us identify whether:

The schema file is being loaded correctly
The prompt is too long for the model
The LLM is actually generating output that we're not capturing properly



It was the prompt. Here's another issue: The outputted SQL is not recognized by the iLab script:

Enter your question: How many mortgages have a loan value greater than the applicant income?

Generating SQL query...
Llama.generate: 1837 prefix-match hit, remaining 1 prompt tokens to eval
llama_perf_context_print:        load time =   15624.94 ms
llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)
llama_perf_context_print:        eval time =    1933.10 ms /    40 runs   (   48.33 ms per token,    20.69 tokens per second)
llama_perf_context_print:       total time =    1936.63 ms /    41 tokens
LLM Response: SELECT COUNT() 
        FROM Preliminary 
        WHERE loan_amount_000s > applicant_income_000s;
Extracted SQL Query: SELECT COUNT() 
        FROM Preliminary 
        WHERE loan_amount_000s > applicant_income_000s;

Executing query on ILAB...

Query Result:
SELECT COUNT(*) 
        FROM Preliminary 
        WHERE loan_amount_000s > applicant_income_000s;
No command-line argument provided. Reading query from stdin...
Error: No query provided via argument or stdin pipe.
Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"
Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py

Also I want to get rid of this: 

Llama.generate: 1837 prefix-match hit, remaining 1 prompt tokens to eval
llama_perf_context_print:        load time =   15624.94 ms
llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)
llama_perf_context_print:        eval time =    1933.10 ms /    40 runs   (   48.33 ms per token,    20.69 tokens per second)
llama_perf_context_print:       total time =    1936.63 ms /    41 tokens

Edit
Looking at the output, there are two issues:

The query has newlines and tabs, which isn't being handled properly when sent to stdin
The LLM debug output is showing up (the performance stats)
Let's fix both:


Final Fixed DatabaseLLM Script
Code 
The key changes:

Added verbose=False to the Llama constructor to disable the debug output
Updated generate_query to append the semicolon directly
Updated extract_sql_query to clean up the query with re.sub(r'\s+', ' ', llm_response).strip() which replaces all consecutive whitespace characters with a single space
Updated execute_query_on_ilab to ensure the query is sent as a single line with .replace('\n', ' ') before sending to stdin
This should fix both issues:

The LLM performance stats won't show up anymore
The SQL query will be sent as a clean single line to the iLab script



So do I remove everything from extract_sql_query and replace it with this code?

Edit
No, don't remove everything. I'm showing the updated extract_sql_query method. Here's the complete method for clarity:

python
def extract_sql_query(self, llm_response):
    # Clean up the query - remove extra whitespace and make it a single line
    cleaned_query = re.sub(r'\s+', ' ', llm_response).strip()
    if not cleaned_query.endswith(';'):
        cleaned_query += ';'
    return cleaned_query
This is much simpler than the original method that had all the pattern matching. The original method was looking for SQL patterns within the response, but now we can simplify because:

We know the LLM response will be SQL (we don't need to extract it from explanatory text)
We just need to clean up formatting (remove extra whitespace/newlines)
We ensure it ends with a semicolon
So yes, replace the entire original extract_sql_query method with this simpler version.




Enter your question: How many mortgages have a loan value greater than the applicant income?

Generating SQL query...
LLM Response: 
 SELECTSELECT COUNT() FROM Preliminary WHERE loan_amount_000s > applicant_income_000s;
Extracted SQL Query: 
 SELECTSELECT COUNT() FROM Preliminary WHERE loan_amount_000s > applicant_income_000s;

Executing query on ILAB...

Query Result:
SELECTSELECT COUNT(*) FROM Preliminary WHERE loan_amount_000s > applicant_income_000s;
No command-line argument provided. Reading query from stdin...
Error: No query provided via argument or stdin pipe.
Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"
Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py

Edit
The issue is that the query has "SELECTSELECT" instead of just "SELECT". This is happening because the prompt already includes "SELECT" and the LLM is adding another "SELECT". Let's fix the prompt:


Final Fixed DatabaseLLM Script
Code ∙ Version 2 
The fix:

Changed the prompt ending from "SELECT" to "Query:"
Removed the concatenation of "SELECT" to the output since the LLM will include it in its response
This should prevent the "SELECTSELECT" issue.




Enter your question: How many mortgages have a loan value greater than the applicant income?

Generating SQL query...
LLM Response: 
 sql
        SELECT COUNT(*) AS count_high_value_loans
        FROM Preliminary
        WHERE loan_amount_000s > CAST(applicant_income_000s AS NUMERIC);
        ;
Extracted SQL Query: 
 sql SELECT COUNT(*) AS count_high_value_loans FROM Preliminary WHERE loan_amount_000s > CAST(applicant_income_000s AS NUMERIC); ;

Executing query on ILAB...

Query Result:
sql SELECT COUNT(*) AS count_high_value_loans FROM Preliminary WHERE loan_amount_000s > CAST(applicant_income_000s AS NUMERIC); ;
No command-line argument provided. Reading query from stdin...
Error: No query provided via argument or stdin pipe.
Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"
Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py

Edit
The issue now is that the LLM is generating the query with markdown code block formatting (```) but our extraction isn't removing this properly. Let's fix the extract_sql_query method to handle this:


Final Fixed DatabaseLLM Script
Code ∙ Version 3 
Now the extract_sql_query method will:

Remove any markdown code block markers (```) and language tags (sql)
Clean up extra whitespace to make it a single line
Ensure it ends with a semicolon
This should properly extract just the SQL query without the markdown formatting.




Generating SQL query...
LLM Response: 
 ;
Extracted SQL Query: 
 ;

Executing query on ILAB...

Query Result:
;
No command-line argument provided. Reading query from stdin...
Error: No query provided via argument or stdin pipe.
Usage (Argument): python3 ilab_script.py "SELECT * FROM your_table LIMIT 5;"
Usage (Stdin): echo "SELECT * FROM your_table LIMIT 5;" | python3 ilab_script.py

Edit
The LLM is only generating a semicolon. This might be due to the stop token being triggered too early. Let's fix the generate_query method:


Final Fixed DatabaseLLM Script
Code ∙ Version 4 
I changed the stop token from ";" to "\n\n" because the semicolon was causing the LLM to stop immediately. Now it will let the LLM complete the query and we'll add the semicolon ourselves if needed.

##### This did not help, and I ended up fixing it myself by tweaking the prompt #####
##### Claude was pretty useless apart from helping with testing the ssh connection #####
